# Medical-Vision-and-Language-Tasks-and-Methodologies-A-Survey
Medical Vision-and-Language Tasks and Methodologies: A Survey

## List of related papers and code

### Medical Multi-modal Diagnosis and Prognosis


- **Xplainer:** Pellegrini, Chantal and Keicher, Matthias and {\"O}zsoy, Ege and Jiraskova, Petra and Braren, Rickmer and Navab, Nassir.<br> "Xplainer: From x-ray observations to explainable zero-shot diagnosis" **MICCAI (2023).** [[paper](https://arxiv.org/pdf/2303.13391)] [[code](https://github.com/ChantalMP/Xplainer)]

- Zhong, Yi and Xu, Mengqiu and Liang, Kongming and Chen, Kaixin and Wu, Ming.<br> "Ariadne's Thread: Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray Images" **MICCAI (2023).** [[paper](https://arxiv.org/pdf/2307.03942)] [[code](https://github.com/Junelin2333/LanGuideMedSeg-MICCAI2023)]

- **CLIP-Lung:** Lei, Yiming and Li, Zilong and Shen, Yan and Zhang, Junping and Shan, Hongming.<br> "CLIP-Lung: Textual knowledge-guided lung nodule malignancy prediction" **MICCAI (2023).** [[paper](https://arxiv.org/pdf/2304.08013)] 

- **GSDG:** Chen, Shouyu and Guo, Xin and Zhu, Jianping and Wang, Yin.<br> "GSDG: Exploring a Global Semantic-Guided Dual-Stream Graph Model for Automated Volume Differential Diagnosis and Prognosis" **MICCAI (2023).** [[paper](https://link.springer.com/chapter/10.1007/978-3-031-43904-9_45)]

- Ichinose, Akimichi and Hatsutani, Taro and Nakamura, Keigo and Kitamura, Yoshiro and Iizuka, Satoshi and Simo-Serra, Edgar and Kido, Shoji and Tomiyama, Noriyuki.<br> "Visual grounding of whole radiology reports for 3d ct images" **MICCAI (2023).** [[paper](https://arxiv.org/pdf/2312.04794)]

- Liu, Jiaxiang and Hu, Tianxiang and Zhang, Yan and Gai, Xiaotang and Feng, Yang and Liu, Zuozhu.<br> "A chatgpt aided explainable framework for zero-shot medical image diagnosis" **arXiv (2023).** [[paper](https://arxiv.org/pdf/2307.01981)]

- **WSI-MTMI:** Liu, Jianxin and Ge, Rongjun and Wan, Peng and Zhu, Qi and Zhang, Daoqiang and Shao, Wei.<br> "Multi-task multi-instance learning for jointly diagnosis and prognosis of early-stage breast invasive carcinoma from whole-slide pathological images" **IPMI (2023).** [[paper](https://link.springer.com/chapter/10.1007/978-3-031-34048-2_12)]

- Song, Xuegang and Zhou, Feng and Frangi, Alejandro F and Cao, Jiuwen and Xiao, Xiaohua and Lei, Yi and Wang, Tianfu and Lei, Baiying.<br> "Multicenter and multichannel pooling GCN for early AD diagnosis based on dual-modality fused brain network" **TMI (2022).** [[paper](https://ieeexplore.ieee.org/abstract/document/9810283)] [[code](https://github.com/Xuegang-S)]

- Mehta, Sachin and Lu, Ximing and Wu, Wenjun and Weaver, Donald and Hajishirzi, Hannaneh and Elmore, Joann G and Shapiro, Linda G.<br> "End-to-end diagnosis of breast biopsy images with transformers" **Medical image analysis (2022).** [[paper](https://www.sciencedirect.com/science/article/pii/S136184152200113X)] 

- **${M^2F}$:** Lu, Zilin and Lu, Mengkang and Xia, Yong.<br> "M2F: A Multi-modal and Multi-task Fusion Network for Glioma Diagnosis and Prognosis" **MICCAI (2022).** [[paper](https://link.springer.com/chapter/10.1007/978-3-031-18814-5_1)]

- **BERTHop:** Monajatipoor, Masoud and Rouhsedaghat, Mozhdeh and Li, Liunian Harold and Jay Kuo, C-C and Chien, Aichi and Chang, Kai-Wei.<br> "Berthop: An effective vision-and-language model for chest x-ray disease diagnosis" **MICCAI (2022).** [[paper](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_69)] [[code](https://github.com/masoud-monajati/BERTHop)]

- Kim, Daekyung and Nam, Chang-Mo and Park, Haesol and Jang, Mijung and Lee, Kyong Joon.<br> "Weakly supervised branch network with template mask for classifying masses in 3D automated breast ultrasound" **WACV (2022).** [[paper](https://openaccess.thecvf.com/content/WACV2022/papers/Kim_Weakly_Supervised_Branch_Network_With_Template_Mask_for_Classifying_Masses_WACV_2022_paper.pdf)] 

- Wu, Yujiao and Wang, Yaxiong and Huang, Xiaoshui and Yang, Fan and Ling, Sai Ho and Su, Steven Weidong.<br> "Multimodal Learning for Non-small Cell Lung Cancer Prognosis" **arXiv (2022).** [[paper](https://arxiv.org/pdf/2211.03280)]

- Tan, Kaiwen and Huang, Weixian and Liu, Xiaofeng and Hu, Jinlong and Dong, Shoubin.<br> "A multi-modal fusion framework based on multi-task correlation learning for cancer prognosis prediction" **Artificial Intelligence in Medicine (2022).** [[paper](https://www.sciencedirect.com/science/article/pii/S0933365722000252)]

- Chen, Yifei and Li, Dandan and Zhang, Xin and Jin, Jing and Shen, Yi.<br> "Computer aided diagnosis of thyroid nodules based on the devised small-datasets multi-view ensemble learning" **Medical Image Analysis (2021).** [[paper](https://www.sciencedirect.com/science/article/pii/S1361841520301833)]

- Gündel, Sebastian and Setio, Arnaud AA and Ghesu, Florin C and Grbic, Sasa and Georgescu, Bogdan and Maier, Andreas and Comaniciu, Dorin.<br> "Robust classification from noisy labels: Integrating additional knowledge for chest radiography abnormality assessment" **Medical Image Analysis (2021).** [[paper](https://arxiv.org/pdf/2104.05261)]

- Qiu, Di and Lui, Lok Ming.<br> "Modal Uncertainty Estimation for Medical Imaging Based Diagnosis" **MICCAI (2021).** [[paper](https://link.springer.com/chapter/10.1007/978-3-030-87735-4_1)]

- Bhalodia, Riddhish and Hatamizadeh, Ali and Tam, Leo and Xu, Ziyue and Wang, Xiaosong and Turkbey, Evrim and Xu, Daguang.<br> "Improving pneumonia localization via cross-attention on medical images and reports" **MICCAI (2021).** [[paper](https://arxiv.org/pdf/2110.03094)]

- Sekuboyina, Anjany and Oñoro-Rubio, Daniel and Kleesiek, Jens and Malone, Brandon.<br> "A relational-learning perspective to multi-label chest X-ray classification" **ISBI (2021).** [[paper](https://arxiv.org/pdf/2103.06220)]

- Wu, Joy and Gur, Yaniv and Karargyris, Alexandros and Syed, Ali Bin and Boyko, Orest and Moradi, Mehdi and Syeda-Mahmood, Tanveer.<br> "Automatic bounding box annotation of chest x-ray data for localization of abnormalities" **ISBI (2020).** [[paper](https://ieeexplore.ieee.org/abstract/document/9098482)]

- Chauhan, Geeticka and Liao, Ruizhi and Wells, William and Andreas, Jacob and Wang, Xin and Berkowitz, Seth and Horng, Steven and Szolovits, Peter and Golland, Polina.<br> "Joint modeling of chest radiographs and radiology reports for pulmonary edema assessment" **MICCAI (2020).** [[paper](https://link.springer.com/chapter/10.1007/978-3-030-59713-9_51)] [[code](https://github.com/RayRuizhiLiao/joint_chestxray)]

- van Sonsbeek, Tom and Worring, Marcel.<br> "Towards automated diagnosis with attentive multi-modal learning using electronic health records and chest x-rays" **MICCAI (2020).** [[paper](https://link.springer.com/chapter/10.1007/978-3-030-60946-7_11)]

- Tian, Jiang and Zhong, Cheng and Shi, Zhongchao and Xu, Feiyu.<br> "Towards automatic diagnosis from multi-modal medical data" **MICCAI (2019).** [[paper](https://link.springer.com/chapter/10.1007/978-3-030-33850-3_8)]

- **DGM2FS:** Shao, Wei and Wang, Tongxin and Huang, Zhi and Cheng, Jun and Han, Zhi and Zhang, Daoqiang and Huang, Kun.<br> "Diagnosis-guided multi-modal feature selection for prognosis prediction of lung squamous cell carcinoma" **MICCAI (2019).** [[paper](https://link.springer.com/chapter/10.1007/978-3-030-32251-9_13)]

- Pelka, Obioma and Nensa, Felix and Friedrich, Christoph M.<br> "Branding-fusion of meta data and musculoskeletal radiographs for multi-modal diagnostic recognition" **ICCV (2019).** [[paper](https://openaccess.thecvf.com/content_ICCVW_2019/papers/VRMI/Pelka_Branding_-_Fusion_of_Meta_Data_and_Musculoskeletal_Radiographs_for_ICCVW_2019_paper.pdf)]

### Medical Image Segmentation

- **LViT:** Li, Zihan and Li, Yunxiang and Li, Qingde and Wang, Puyang and Guo, Dazhou and Lu, Le and Jin, Dakai and Zhang, You and Hong, Qingqi.<br> "Lvit: language meets vision transformer in medical image segmentation" **TMI (2024).** [[paper](https://arxiv.org/pdf/2206.14718)] [[code](https://github.com/HUANGLIZI/LViT)]

- **SaLIP:** Aleem, Sidra and Wang, Fangyijie and Maniparambil, Mayug and Arazo, Eric and Dietlmeier, Julia and Curran, Kathleen and Connor, Noel EO' and Little, Suzanne.<br> "Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero-shot Medical Image Segmentation" **CVPR (2024).** [[paper](https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/papers/Aleem_Test-Time_Adaptation_with_SaLIP_A_Cascade_of_SAM_and_CLIP_CVPRW_2024_paper.pdf)] [[code](https://github.com/aleemsidra/SaLIP)]

- **SegICL:** Shen, Lingdong and Shang, Fangxin and Yang, Yehui and Huang, Xiaoshuang and Xiang, Shining.<br> "SegICL: A Universal In-context Learning Framework for Enhanced Segmentation in Medical Imaging" **arXiv (2024).** [[paper](https://arxiv.org/pdf/2403.16578)]

- **MedCLIP-SAM:** Koleilat, Taha and Asgariandehkordi, Hojat and Rivaz, Hassan and Xiao, Yiming.<br> "MedCLIP-SAM: Bridging text and image towards universal medical image segmentation" **arXiv (2024).** [[paper](https://arxiv.org/pdf/2403.20253)] [[code](https://github.com/HealthX-Lab/MedCLIP-SAM)]

- Kunhimon, Shahina and Naseer, Muzammal and Khan, Salman and Khan, Fahad Shahbaz.<br> "Language Guided Domain Generalized Medical Image Segmentation" **arXiv (2024).** [[paper](https://arxiv.org/pdf/2404.01272)] [[code](https://github.com/ShahinaKK/LG_SDG)]

- **RecLMIS:** Huang, Xiaoshuang and Li, Hongxiang and Cao, Meng and Chen, Long and You, Chenyu and An, Dong.<br> "Cross-Modal Conditioned Reconstruction for Language-guided Medical Image Segmentation" **arXiv (2024).** [[paper](https://arxiv.org/pdf/2404.02845)] [[code](https://github.com/ShawnHuang497/RecLMIS)]

- **${CPAM^{TG}}$:** Lee, Go-Eun and Kim, Seon Ho and Cho, Jungchan and Choi, Sang Tae and Choi, Sang-Il.<br> "Text-guided cross-position attention for segmentation: Case of medical image" **MICCAI (2023).** [[paper](https://link.springer.com/chapter/10.1007/978-3-031-43904-9_52)] [[code]()]

- **TPRO:** Zhang, Shaoteng and Zhang, Jianpeng and Xie, Yutong and Xia, Yong.<br> "TPRO: Text-Prompting-Based weakly supervised histopathology tissue segmentation" **MICCAI (2023).** [[paper](https://link.springer.com/chapter/10.1007/978-3-031-43907-0_11)] [[code](https://github.com/zhangst431/TPRO)]

- Liu, Jie and Zhang, Yixiao and Chen, Jie-Neng and Xiao, Junfei and Lu, Yongyi and A Landman, Bennett and Yuan, Yixuan and Yuille, Alan and Tang, Yucheng and Zhou, Zongwei.<br> "Clip-driven universal model for organ segmentation and tumor detection" **ICCV (2023).** [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.pdf)] [[code](https://github.com/ljwztc/CLIP-Driven-Universal-Model)]

- Han, Xianjun and Chen, Qianqian and Xie, Zhaoyang and Li, Xuejun and Yang, Hongyu.<br> "Multiscale progressive text prompt network for medical image segmentation" **Computers & Graphics (2023).** [[paper](https://www.sciencedirect.com/science/article/pii/S0097849323002170)]

- Lu, Yixing and Fan, Zhaoxin and Xu, Min.<br> "Multi-dimensional Fusion and Consistency for Semi-supervised Medical Image Segmentation" **International Conference on Multimedia Modeling (2024).** [[paper](https://arxiv.org/pdf/2309.06618)]

- **EMIT-Diff:** Zhang, Zheyuan and Yao, Lanhong and Wang, Bin and Jha, Debesh and Keles, Elif and Medetalibeyoglu, Alpay and Bagci, Ulas.<br> "Emit-diff: Enhancing medical image segmentation via text-guided diffusion model" **arXiv (2023).** [[paper](https://arxiv.org/pdf/2310.12868)]

- **GTGM:** Chen, Yinda and Liu, Che and Huang, Wei and Cheng, Sibo and Arcucci, Rossella and Xiong, Zhiwei.<br> "Generative text-guided 3d vision-language pretraining for unified medical image segmentation" **arXiv (2023).** [[paper](https://arxiv.org/pdf/2306.04811)]

- **Bi-VLGM:** Wenting, Chen and Jie, Liu and Yixuan, Yuan.<br> "Bi-VLGM: Bi-Level Class-Severity-Aware Vision-Language Graph Matching for Text Guided Medical Image Segmentation" **arXiv (2023).** [[paper](https://arxiv.org/pdf/2305.12231)]

- Segre, Leo and Hirschorn, Or and Ginzburg, Dvir and Raviv, Dan.<br> "Shape-consistent generative adversarial networks for multi-modal medical segmentation maps" **ISBI (2022).** [[paper](https://arxiv.org/pdf/2201.09693)] [[code](https://github.com/orhir/3D-Shape-Consistent-GAN)]

- **DTAN:** Zhao, Yiyang and Li, Jinjiang and Ren, Lu and Chen, Zheng.<br> "DTAN: Diffusion-based Text Attention Network for medical image segmentation" **Computers in Biology and Medicine (2024).** [[paper](https://www.sciencedirect.com/science/article/pii/S0010482523011939)]

- **TGEDiff:** Dong, Zhiwei and Yuan, Genji and Hua, Zhen and Li, Jinjiang.<br> "Diffusion model-based text-guided enhancement network for medical image segmentation" **Expert Systems with Applications (2024).** [[paper](https://www.sciencedirect.com/science/article/pii/S0957417424004147)]
